{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f06724e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for the first 5 valid data points...\n",
      "\n",
      "\n",
      "--- Valid Point 1 ---\n",
      "Latitude: -55.625, Longitude: -68.125\n",
      "Swnet_tavg: 127.89435577392578\n",
      "Lwnet_tavg: -43.81508255004883\n",
      "Qle_tavg: 45.2786750793457\n",
      "Qh_tavg: 38.90801239013672\n",
      "Qg_tavg: -0.17432762682437897\n",
      "Snowf_tavg: 0.0\n",
      "Rainf_tavg: 3.5384677175898105e-05\n",
      "Evap_tavg: 1.8101132809533738e-05\n",
      "Qs_acc: 0.0013320967555046082\n",
      "Qsb_acc: 0.04082737863063812\n",
      "Qsm_acc: 0.0\n",
      "AvgSurfT_inst: 279.7496337890625\n",
      "Albedo_inst: 14.0\n",
      "SWE_inst: 0.0\n",
      "SnowDepth_inst: 0.0\n",
      "SoilMoi0_10cm_inst: 26.130611419677734\n",
      "SoilMoi10_40cm_inst: 77.51742553710938\n",
      "SoilMoi40_100cm_inst: 150.65809631347656\n",
      "SoilMoi100_200cm_inst: 242.81396484375\n",
      "SoilTMP0_10cm_inst: 279.7696838378906\n",
      "SoilTMP10_40cm_inst: 279.8160705566406\n",
      "SoilTMP40_100cm_inst: 279.7863464355469\n",
      "SoilTMP100_200cm_inst: 279.61016845703125\n",
      "PotEvap_tavg: 109.39259338378906\n",
      "ECanop_tavg: 19.019193649291992\n",
      "Tveg_tavg: 2.8281047344207764\n",
      "ESoil_tavg: 23.450363159179688\n",
      "RootMoist_inst: 497.1201477050781\n",
      "CanopInt_inst: 0.24774493277072906\n",
      "Wind_f_inst: 8.55028247833252\n",
      "Rainf_f_tavg: 3.5384677175898105e-05\n",
      "Tair_f_inst: 279.19512939453125\n",
      "Qair_f_inst: 0.00514546362683177\n",
      "Psurf_f_inst: 97167.0703125\n",
      "SWdown_f_tavg: 148.7144012451172\n",
      "LWdown_f_tavg: 301.4101867675781\n",
      "\n",
      "--- Valid Point 2 ---\n",
      "Latitude: -55.375, Longitude: -69.625\n",
      "Swnet_tavg: 125.06580352783203\n",
      "Lwnet_tavg: -38.63431930541992\n",
      "Qle_tavg: 37.06976318359375\n",
      "Qh_tavg: 50.11643981933594\n",
      "Qg_tavg: -0.8189244270324707\n",
      "Snowf_tavg: 0.0\n",
      "Rainf_tavg: 3.773588832700625e-05\n",
      "Evap_tavg: 1.4820487194810994e-05\n",
      "Qs_acc: 0.001502137049101293\n",
      "Qsb_acc: 0.06472495943307877\n",
      "Qsm_acc: 2.0161289739917265e-06\n",
      "AvgSurfT_inst: 278.94085693359375\n",
      "Albedo_inst: 14.004655838012695\n",
      "SWE_inst: 0.0012955465354025364\n",
      "SnowDepth_inst: 8.097165846265852e-06\n",
      "SoilMoi0_10cm_inst: 26.882457733154297\n",
      "SoilMoi10_40cm_inst: 79.89959716796875\n",
      "SoilMoi40_100cm_inst: 155.59654235839844\n",
      "SoilMoi100_200cm_inst: 251.5914306640625\n",
      "SoilTMP0_10cm_inst: 279.0068359375\n",
      "SoilTMP10_40cm_inst: 279.1996154785156\n",
      "SoilTMP40_100cm_inst: 279.3155212402344\n",
      "SoilTMP100_200cm_inst: 279.2893371582031\n",
      "PotEvap_tavg: 81.827392578125\n",
      "ECanop_tavg: 17.125926971435547\n",
      "Tveg_tavg: 1.1239919662475586\n",
      "ESoil_tavg: 18.82883071899414\n",
      "RootMoist_inst: 379.8659362792969\n",
      "CanopInt_inst: 0.3150283396244049\n",
      "Wind_f_inst: 9.1737642288208\n",
      "Rainf_f_tavg: 3.773588832700625e-05\n",
      "Tair_f_inst: 278.2695617675781\n",
      "Qair_f_inst: 0.0052598766051232815\n",
      "Psurf_f_inst: 96357.0078125\n",
      "SWdown_f_tavg: 145.4280242919922\n",
      "LWdown_f_tavg: 302.5395812988281\n",
      "\n",
      "--- Valid Point 3 ---\n",
      "Latitude: -55.375, Longitude: -69.375\n",
      "Swnet_tavg: 126.8281021118164\n",
      "Lwnet_tavg: -39.892059326171875\n",
      "Qle_tavg: 34.90730285644531\n",
      "Qh_tavg: 52.753089904785156\n",
      "Qg_tavg: -0.7968276143074036\n",
      "Snowf_tavg: 8.467742063089645e-09\n",
      "Rainf_tavg: 3.676814594655298e-05\n",
      "Evap_tavg: 1.3956777365820017e-05\n",
      "Qs_acc: 0.0015320967650040984\n",
      "Qsb_acc: 0.056999314576387405\n",
      "Qsm_acc: 1.6129032474054839e-06\n",
      "AvgSurfT_inst: 279.2513732910156\n",
      "Albedo_inst: 14.003157615661621\n",
      "SWE_inst: 0.0012145749060437083\n",
      "SnowDepth_inst: 8.097165846265852e-06\n",
      "SoilMoi0_10cm_inst: 26.831668853759766\n",
      "SoilMoi10_40cm_inst: 79.69053649902344\n",
      "SoilMoi40_100cm_inst: 154.7271728515625\n",
      "SoilMoi100_200cm_inst: 249.00767517089844\n",
      "SoilTMP0_10cm_inst: 279.3173828125\n",
      "SoilTMP10_40cm_inst: 279.5127868652344\n",
      "SoilTMP40_100cm_inst: 279.6248474121094\n",
      "SoilTMP100_200cm_inst: 279.5970153808594\n",
      "PotEvap_tavg: 75.49848175048828\n",
      "ECanop_tavg: 16.318063735961914\n",
      "Tveg_tavg: 1.3333871364593506\n",
      "ESoil_tavg: 17.314071655273438\n",
      "RootMoist_inst: 427.9012451171875\n",
      "CanopInt_inst: 0.3236558735370636\n",
      "Wind_f_inst: 8.489958763122559\n",
      "Rainf_f_tavg: 3.677661152323708e-05\n",
      "Tair_f_inst: 278.5038757324219\n",
      "Qair_f_inst: 0.0053939251229166985\n",
      "Psurf_f_inst: 96915.125\n",
      "SWdown_f_tavg: 147.47633361816406\n",
      "LWdown_f_tavg: 302.97509765625\n",
      "\n",
      "--- Valid Point 4 ---\n",
      "Latitude: -55.375, Longitude: -68.875\n",
      "Swnet_tavg: 121.71540069580078\n",
      "Lwnet_tavg: -39.45411682128906\n",
      "Qle_tavg: 35.397789001464844\n",
      "Qh_tavg: 47.539100646972656\n",
      "Qg_tavg: -0.7160211801528931\n",
      "Snowf_tavg: 9.879032347726024e-08\n",
      "Rainf_tavg: 3.522379120113328e-05\n",
      "Evap_tavg: 1.4153954907669686e-05\n",
      "Qs_acc: 0.0015003628795966506\n",
      "Qsb_acc: 0.054155442863702774\n",
      "Qsm_acc: 2.419354814264807e-06\n",
      "AvgSurfT_inst: 278.8245544433594\n",
      "Albedo_inst: 14.00603199005127\n",
      "SWE_inst: 0.0027935223188251257\n",
      "SnowDepth_inst: 1.8218623154098168e-05\n",
      "SoilMoi0_10cm_inst: 26.668214797973633\n",
      "SoilMoi10_40cm_inst: 79.24935150146484\n",
      "SoilMoi40_100cm_inst: 154.1339874267578\n",
      "SoilMoi100_200cm_inst: 248.09725952148438\n",
      "SoilTMP0_10cm_inst: 278.8837890625\n",
      "SoilTMP10_40cm_inst: 279.0594482421875\n",
      "SoilTMP40_100cm_inst: 279.1456604003906\n",
      "SoilTMP100_200cm_inst: 279.1024169921875\n",
      "PotEvap_tavg: 77.5325927734375\n",
      "ECanop_tavg: 16.457782745361328\n",
      "Tveg_tavg: 1.5091935396194458\n",
      "ESoil_tavg: 17.495201110839844\n",
      "RootMoist_inst: 464.4304504394531\n",
      "CanopInt_inst: 0.31446558237075806\n",
      "Wind_f_inst: 7.780646800994873\n",
      "Rainf_f_tavg: 3.5322984331287444e-05\n",
      "Tair_f_inst: 278.1098937988281\n",
      "Qair_f_inst: 0.005206030327826738\n",
      "Psurf_f_inst: 95859.828125\n",
      "SWdown_f_tavg: 141.53330993652344\n",
      "LWdown_f_tavg: 301.4031982421875\n",
      "\n",
      "--- Valid Point 5 ---\n",
      "Latitude: -55.375, Longitude: -68.625\n",
      "Swnet_tavg: 124.33600616455078\n",
      "Lwnet_tavg: -41.180850982666016\n",
      "Qle_tavg: 36.42540740966797\n",
      "Qh_tavg: 47.294342041015625\n",
      "Qg_tavg: -0.5520292520523071\n",
      "Snowf_tavg: 8.387096528394977e-08\n",
      "Rainf_tavg: 3.468104841886088e-05\n",
      "Evap_tavg: 1.4564438970410265e-05\n",
      "Qs_acc: 0.0014971774071455002\n",
      "Qsb_acc: 0.05423205718398094\n",
      "Qsm_acc: 6.854838829895016e-06\n",
      "AvgSurfT_inst: 278.5738525390625\n",
      "Albedo_inst: 14.0126314163208\n",
      "SWE_inst: 0.00473684212192893\n",
      "SnowDepth_inst: 3.1578947528032586e-05\n",
      "SoilMoi0_10cm_inst: 26.5801944732666\n",
      "SoilMoi10_40cm_inst: 78.98485565185547\n",
      "SoilMoi40_100cm_inst: 153.77691650390625\n",
      "SoilMoi100_200cm_inst: 248.1826171875\n",
      "SoilTMP0_10cm_inst: 278.6233215332031\n",
      "SoilTMP10_40cm_inst: 278.7841796875\n",
      "SoilTMP40_100cm_inst: 278.83642578125\n",
      "SoilTMP100_200cm_inst: 278.7642822265625\n",
      "PotEvap_tavg: 81.74541473388672\n",
      "ECanop_tavg: 16.538265228271484\n",
      "Tveg_tavg: 1.7029435634613037\n",
      "ESoil_tavg: 18.266855239868164\n",
      "RootMoist_inst: 422.2461242675781\n",
      "CanopInt_inst: 0.30170848965644836\n",
      "Wind_f_inst: 7.47052526473999\n",
      "Rainf_f_tavg: 3.4764918382279575e-05\n",
      "Tair_f_inst: 277.8477478027344\n",
      "Qair_f_inst: 0.005078823771327734\n",
      "Psurf_f_inst: 95174.84375\n",
      "SWdown_f_tavg: 144.5855712890625\n",
      "LWdown_f_tavg: 298.2239074707031\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "ds = xr.open_dataset(\"D:\\Groundwater Vulnerability Mapping\\data\\RAW Data\\GLDAS_NOAH025_M_2.1-20250814_151559\\GLDAS_NOAH025_M.A200001.021.nc4\")  # Replace with your filename\n",
    "\n",
    "# Get lat/lon arrays\n",
    "lats = ds['lat'].values\n",
    "lons = ds['lon'].values\n",
    "\n",
    "# List of variables (excluding time_bnds which is not spatial)\n",
    "variables = [var for var in ds.data_vars if set(ds[var].dims) >= {'lat', 'lon'}]\n",
    "\n",
    "valid_points_found = 0\n",
    "\n",
    "print(f\"Searching for the first 5 valid data points...\\n\")\n",
    "\n",
    "for i, lat in enumerate(lats):\n",
    "    for j, lon in enumerate(lons):\n",
    "        # Check if at least one variable at this lat-lon has non-NaN data\n",
    "        has_valid_data = False\n",
    "        for var in variables:\n",
    "            val = ds[var].isel(time=0, lat=i, lon=j).values\n",
    "            if not np.isnan(val):\n",
    "                has_valid_data = True\n",
    "                break\n",
    "        \n",
    "        if has_valid_data:\n",
    "            print(f\"\\n--- Valid Point {valid_points_found + 1} ---\")\n",
    "            print(f\"Latitude: {lat}, Longitude: {lon}\")\n",
    "\n",
    "            for var in variables:\n",
    "                val = ds[var].isel(time=0, lat=i, lon=j).values\n",
    "                print(f\"{var}: {val}\")\n",
    "\n",
    "            valid_points_found += 1\n",
    "        \n",
    "        if valid_points_found >= 5:\n",
    "            break\n",
    "    if valid_points_found >= 5:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "935c697b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Latitude  Longitude  SoilMoist_S_inst  SoilMoist_RZ_inst  SoilMoist_P_inst\n",
      "0      65.5     -149.5          4.591129         213.517609        842.301880\n",
      "1      54.5      -84.5          6.437433         324.279907       2218.286133\n",
      "2      22.5       96.5          5.582534         280.239075       1851.348877\n",
      "3      53.5      115.5          5.490380         265.944000        950.356689\n",
      "4      54.5      -62.5          7.143635         365.173126       1312.962646\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "file_path = 'D:\\Groundwater Vulnerability Mapping\\data\\RAW Data\\GLDAS_CLSM10_M_2.1-20250814_153125\\GLDAS_CLSM10_M.A200001.021.nc4'  # Update this to your actual file path\n",
    "ds = xr.open_dataset(file_path)\n",
    "\n",
    "# Use the first time step\n",
    "time_step = ds['time'][0]\n",
    "\n",
    "# Choose one variable to find valid data locations (e.g., Surface Soil Moisture)\n",
    "valid_mask = ~np.isnan(ds['SoilMoist_S_inst'].sel(time=time_step))\n",
    "\n",
    "# Get the indices of valid (lat, lon) pairs\n",
    "valid_points = np.array(np.where(valid_mask.values)).T\n",
    "\n",
    "# If there are fewer than 5 valid points\n",
    "if len(valid_points) < 5:\n",
    "    raise ValueError(\"Not enough valid data points in the dataset.\")\n",
    "\n",
    "# Randomly select 5 valid points\n",
    "np.random.seed(42)\n",
    "selected_indices = valid_points[np.random.choice(len(valid_points), 5, replace=False)]\n",
    "\n",
    "# Get lat/lon values\n",
    "lats = ds['lat'].values\n",
    "lons = ds['lon'].values\n",
    "\n",
    "# Collect data\n",
    "data = []\n",
    "for idx in selected_indices:\n",
    "    lat_idx, lon_idx = idx\n",
    "    lat = lats[lat_idx]\n",
    "    lon = lons[lon_idx]\n",
    "\n",
    "    s = ds['SoilMoist_S_inst'].sel(lat=lat, lon=lon, time=time_step, method='nearest').item()\n",
    "    rz = ds['SoilMoist_RZ_inst'].sel(lat=lat, lon=lon, time=time_step, method='nearest').item()\n",
    "    p = ds['SoilMoist_P_inst'].sel(lat=lat, lon=lon, time=time_step, method='nearest').item()\n",
    "\n",
    "    data.append({\n",
    "        'Latitude': lat,\n",
    "        'Longitude': lon,\n",
    "        'SoilMoist_S_inst': s,\n",
    "        'SoilMoist_RZ_inst': rz,\n",
    "        'SoilMoist_P_inst': p\n",
    "    })\n",
    "\n",
    "# Display results\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd641af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Latitude  Longitude  SoilMoi0_30cm_inst  SoilMoi_depth2_inst  \\\n",
      "0      65.5     -149.5           84.679436           138.185181   \n",
      "1      54.5      -84.5          113.104263           143.242996   \n",
      "2      22.5       96.5           56.632904           262.413757   \n",
      "3      53.5      115.5           85.961090           122.601730   \n",
      "4      54.5      -62.5          121.322533           105.368515   \n",
      "\n",
      "   SoilMoi_depth3_inst  RootMoist_inst  \n",
      "0            21.403254      244.212296  \n",
      "1            18.197269      274.562775  \n",
      "2            22.713724      319.046692  \n",
      "3            22.672068      231.266907  \n",
      "4            24.721439      251.402374  \n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Path to GLDAS VIC NetCDF file\n",
    "file_path = 'D:\\Groundwater Vulnerability Mapping\\data\\RAW Data\\GLDAS_VIC10_M_2.1-20250814_153905\\GLDAS_VIC10_M.A200001.021.nc4'  # Change this to your actual file path\n",
    "ds = xr.open_dataset(file_path)\n",
    "\n",
    "# Define target variables\n",
    "variables = [\n",
    "    'SoilMoi0_30cm_inst',\n",
    "    'SoilMoi_depth2_inst',\n",
    "    'SoilMoi_depth3_inst',\n",
    "    'RootMoist_inst'\n",
    "]\n",
    "\n",
    "# Check all variables exist\n",
    "for var in variables:\n",
    "    if var not in ds:\n",
    "        raise ValueError(f\"Variable '{var}' not found in dataset.\")\n",
    "\n",
    "# Use the first time step\n",
    "time_step = ds['time'][0]\n",
    "\n",
    "# Create a mask of valid data (non-NaN) using one variable\n",
    "valid_mask = ~np.isnan(ds['SoilMoi0_30cm_inst'].sel(time=time_step))\n",
    "\n",
    "# Get valid (lat_idx, lon_idx) indices\n",
    "valid_points = np.array(np.where(valid_mask.values)).T\n",
    "\n",
    "# Ensure there are enough valid points\n",
    "if len(valid_points) < 5:\n",
    "    raise ValueError(\"Not enough valid data points in the dataset.\")\n",
    "\n",
    "# Randomly select 5 valid points\n",
    "np.random.seed(42)\n",
    "selected_indices = valid_points[np.random.choice(len(valid_points), 5, replace=False)]\n",
    "\n",
    "# Extract coordinates\n",
    "lats = ds['lat'].values\n",
    "lons = ds['lon'].values\n",
    "\n",
    "# Collect data\n",
    "data = []\n",
    "for idx in selected_indices:\n",
    "    lat_idx, lon_idx = idx\n",
    "    lat = lats[lat_idx]\n",
    "    lon = lons[lon_idx]\n",
    "\n",
    "    record = {'Latitude': lat, 'Longitude': lon}\n",
    "    for var in variables:\n",
    "        value = ds[var].sel(lat=lat, lon=lon, time=time_step, method='nearest').item()\n",
    "        record[var] = value\n",
    "\n",
    "    data.append(record)\n",
    "\n",
    "# Create a DataFrame and print\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ffede57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diagnosis: No NaN values found. This confirms the data was interpolated at an earlier stage.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load one of your final GWS files (either an individual one or an ensemble one)\n",
    "df = pd.read_csv('grace_processed_clipped_cm.csv')\n",
    "\n",
    "# Check if the main GRACE column has any NaN (missing) values\n",
    "missing_values_exist = df['lwe_thickness_cm'].isna().any()\n",
    "\n",
    "if missing_values_exist:\n",
    "    print(\"Diagnosis: NaN values ARE present. The issue might be with the plotting code.\")\n",
    "else:\n",
    "    print(\"Diagnosis: No NaN values found. This confirms the data was interpolated at an earlier stage.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e8197b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIAGNOSIS: There ARE gaps in your time series. The problem might be with the plotting.\n",
      "Missing months found: DatetimeIndex(['2002-05-01 12:00:00', '2002-06-01 12:00:00',\n",
      "               '2002-07-01 12:00:00', '2002-08-01 12:00:00',\n",
      "               '2002-09-01 12:00:00', '2002-10-01 12:00:00',\n",
      "               '2002-11-01 12:00:00', '2002-12-01 12:00:00',\n",
      "               '2003-01-01 12:00:00', '2003-02-01 12:00:00',\n",
      "               ...\n",
      "               '2024-08-01 12:00:00', '2024-09-01 12:00:00',\n",
      "               '2024-10-01 12:00:00', '2024-11-01 12:00:00',\n",
      "               '2024-12-01 12:00:00', '2025-01-01 12:00:00',\n",
      "               '2025-02-01 12:00:00', '2025-03-01 12:00:00',\n",
      "               '2025-04-01 12:00:00', '2025-05-01 12:00:00'],\n",
      "              dtype='datetime64[ns]', length=276, freq=None)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the final results file\n",
    "df = pd.read_csv('NOAH_GWS_Final_Results_per_Pixel_cm.csv')\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "\n",
    "# Create a complete monthly date range for the period\n",
    "expected_range = pd.date_range(start=df['time'].min(), end=df['time'].max(), freq='MS')\n",
    "\n",
    "# Find which months, if any, are missing from your data's time column\n",
    "# We check against the unique values in the 'time' column\n",
    "missing_months = expected_range.difference(df['time'].unique())\n",
    "\n",
    "if len(missing_months) > 0:\n",
    "    print(\"DIAGNOSIS: There ARE gaps in your time series. The problem might be with the plotting.\")\n",
    "    print(\"Missing months found:\", missing_months)\n",
    "else:\n",
    "    print(\"DIAGNOSIS: There are NO gaps in your time series.\")\n",
    "    print(\"This confirms the source GRACE NetCDF file is a continuous, gap-filled dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7a76b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting memory-efficient read of the single GRACE file...\n",
      "\n",
      "--- DATASET COORDINATES ---\n",
      "Latitude range: -89.75 to 89.75\n",
      "Longitude range: 0.25 to 359.75\n",
      "---------------------------\n",
      "\n",
      "Subsetting data to the study area boundary...\n",
      "Converting the small subset to a DataFrame...\n",
      "\n",
      "✅ SUCCESS: Data loaded into DataFrame without memory error.\n",
      "\n",
      "DIAGNOSIS: Found 245 unique months in the data.\n",
      "Time range found: 2002-04-17 to 2025-05-16\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "# --- Step 1: Define paths and the bounding box for your study area ---\n",
    "grace_single_file_path = r\"D:\\Groundwater Vulnerability Mapping\\data\\RAW Data\\GRACE\\GRCTellus.JPL.200204_202505.GLO.RL06.3M.MSCNv04CRI.nc\"\n",
    "\n",
    "# Define the approximate lat/lon bounds for West Bengal\n",
    "lat_min, lat_max = 21, 28\n",
    "lon_min, lon_max = 85, 90\n",
    "\n",
    "print(\"Attempting memory-efficient read of the single GRACE file...\")\n",
    "\n",
    "try:\n",
    "    # --- Step 2: Open the dataset ---\n",
    "    with xr.open_dataset(grace_single_file_path) as ds:\n",
    "        \n",
    "        # --- NEW: Print coordinate info to see the range ---\n",
    "        print(\"\\n--- DATASET COORDINATES ---\")\n",
    "        print(f\"Latitude range: {ds['lat'].min().item()} to {ds['lat'].max().item()}\")\n",
    "        print(f\"Longitude range: {ds['lon'].min().item()} to {ds['lon'].max().item()}\")\n",
    "        print(\"---------------------------\\n\")\n",
    "\n",
    "        # --- Step 3: Spatially subset the data FIRST ---\n",
    "        print(\"Subsetting data to the study area boundary...\")\n",
    "        # THE FIX: Use the correct slice order for the ascending latitude\n",
    "        grace_subset_xr = ds.sel(lat=slice(lat_min, lat_max), lon=slice(lon_min, lon_max))\n",
    "        \n",
    "        # --- Step 4: Convert the small subset to a DataFrame ---\n",
    "        print(\"Converting the small subset to a DataFrame...\")\n",
    "        grace_df = grace_subset_xr.to_dataframe().reset_index()\n",
    "    \n",
    "    print(\"\\n✅ SUCCESS: Data loaded into DataFrame without memory error.\")\n",
    "    \n",
    "    # --- Step 5: VERIFY the time steps ---\n",
    "    unique_months = grace_df['time'].nunique()\n",
    "    min_date = grace_df['time'].min()\n",
    "    max_date = grace_df['time'].max()\n",
    "    print(f\"\\nDIAGNOSIS: Found {unique_months} unique months in the data.\")\n",
    "    print(f\"Time range found: {min_date.date()} to {max_date.date()}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983358c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- Step 1: Load your final results file (which has gaps) ---\n",
    "gappy_df = pd.read_csv('NOAH_GWS_Final_Results_per_Pixel_cm.csv')\n",
    "gappy_df['time'] = pd.to_datetime(gappy_df['time'])\n",
    "\n",
    "# --- Step 2: Standardize the dates to the 1st of the month ---\n",
    "# We do this first to prepare for the merge\n",
    "gappy_df['time'] = gappy_df['time'].dt.to_period('M').dt.start_time\n",
    "\n",
    "# --- Step 3: Prepare the components for the master grid ---\n",
    "# Get the full, continuous time range\n",
    "full_date_range = pd.date_range(\n",
    "    start=gappy_df['time'].min(), \n",
    "    end=gappy_df['time'].max(), \n",
    "    freq='MS'\n",
    ")\n",
    "full_date_df = pd.DataFrame({'time': full_date_range})\n",
    "\n",
    "# Get all unique pixel coordinates\n",
    "unique_pixels = gappy_df[['lat', 'lon']].drop_duplicates()\n",
    "\n",
    "# --- Step 4: Build the complete master grid (scaffold) ---\n",
    "# This uses a cross join to create a row for every pixel for every month\n",
    "unique_pixels['key'] = 1\n",
    "full_date_df['key'] = 1\n",
    "scaffold_df = pd.merge(full_date_df, unique_pixels, on='key').drop('key', axis=1)\n",
    "\n",
    "# --- Step 5: Merge the gappy data onto the full grid ---\n",
    "# This step adds the data, leaving NaN where months were missing\n",
    "final_gap_filled_df = pd.merge(scaffold_df, gappy_df, on=['time', 'lat', 'lon'], how='left')\n",
    "\n",
    "# --- Step 6: Save the new, gap-filled file ---\n",
    "output_filename = 'GWS_All_Pixels_All_Vars_Gap_Filled.csv'\n",
    "final_gap_filled_df.to_csv(output_filename, index=False)\n",
    "\n",
    "print(f\"✅ Successfully created '{output_filename}'\")\n",
    "print(\"\\n--- Preview of the new gap-filled data ---\")\n",
    "# Let's check a month that we know is a gap (June 2002)\n",
    "# All variable columns should be NaN for this date.\n",
    "print(final_gap_filled_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabfc5df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (groundwater_env)",
   "language": "python",
   "name": "groundwater_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
